//
//  Aesthetic Tendency Analysis.md
//  Project_Color
//
//  Created by Linya Huang on 2025/11/19.
//

# å®¡ç¾å€¾å‘åˆ†æç³»ç»Ÿå®ç°è®¡åˆ’ï¼ˆè‡ªåŠ¨æ¨¡å¼åˆ¤æ–­ç‰ˆï¼‰

## æ ¸å¿ƒç›®æ ‡

æ„å»ºä¸€ä¸ªæ™ºèƒ½çš„å®¡ç¾å€¾å‘åˆ†æç³»ç»Ÿï¼Œèƒ½å¤Ÿï¼š

1. è‡ªåŠ¨æ’é™¤æˆªå±å’Œæ–‡æ¡£ç±»ç…§ç‰‡
2. åŸºäº Vision è¯†åˆ«ç»“æœæ™ºèƒ½åŒ¹é…åœºæ™¯
3. è¿‡æ»¤ç¯å¢ƒå›ºæœ‰è‰²å½©ï¼Œæå–ç”¨æˆ·å®¡ç¾åç§»
4. **è‡ªåŠ¨åˆ¤æ–­åˆ†ææ¨¡å¼**ï¼ˆåŸºäº S/V/C ä¸‰æŒ‡æ ‡ï¼‰
5. ç”Ÿæˆè·¨åœºæ™¯/åœºæ™¯å†…çš„å®¡ç¾å€¾å‘æè¿°

## è‡ªåŠ¨æ¨¡å¼åˆ¤æ–­é€»è¾‘

ç³»ç»Ÿé€šè¿‡ **(S, V, C)** ä¸‰ä¸ªæŒ‡æ ‡è‡ªåŠ¨å†³å®šåˆ†ææ¨¡å¼ï¼š

| æŒ‡æ ‡ | å«ä¹‰ | è®¡ç®—æ–¹æ³• |

|------|------|----------|

| **S** | åœºæ™¯æ•°é‡ | ç»Ÿè®¡ä¸åŒåœºæ™¯ç±»å‹ï¼ˆè¯­ä¹‰è¯†åˆ«ï¼‰ |

| **V** | åç§»ç¨³å®šæ€§ | è®¡ç®—åç§»å‘é‡çš„æ ‡å‡†å·® |

| **C** | ä¸»ä½“ç±»åˆ«æ•° | ç»Ÿè®¡ä¸»ä½“ç±»å‹ï¼ˆäººç‰©/è¡—æ™¯/ç‰©ä»¶ç­‰ï¼‰ |

### æ¨¡å¼åˆ¤å®šè§„åˆ™

| æ¨¡å¼ | æ¡ä»¶ | ç³»ç»Ÿè¡Œä¸º |

|------|------|----------|

| **ç»„å›¾æ¨¡å¼** | S=1 ä¸” Câ‰¤2 ä¸” Vç¨³å®š | å¼ºåŒ–åœºæ™¯å†…é‡å¤ç‰¹å¾ï¼ˆå¦‚è¡—æ‹æš—éƒ¨ç»†èŠ‚ï¼‰ |

| **è¯­è¨€é£æ ¼åŒ¹é…** | S=1 ä¸” C=1 | ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ï¼šè¡—æ‹=åŸå¸‚è‚Œç† / äººåƒ=è‚¤è‰²æƒ…æ„Ÿ |

| **æ··åˆæ¨¡å¼** | Sâ‰¥2 æˆ– Câ‰¥3 | ä¸¥æ ¼æ‰§è¡Œä¸»ä½“è‰²åŸŸäºŒæ¬¡è¿‡æ»¤ã€å½¢æˆè·¨ä¸»é¢˜åç§»å‘é‡ |

| **è·³å˜å®¡ç¾å‹** | Væä¸ç¨³å®š ä¸” Sâ‰¥3 | è¾“å‡ºäººæ ¼æ ‡ç­¾ï¼šå®¡ç¾è·³å˜å‹ / å¤šä¸»é¢˜å‹ |

### é˜ˆå€¼å®šä¹‰

- S åˆ†ç±»ï¼š1 / 2-3ï¼ˆå¼±æ··åˆï¼‰/ â‰¥4ï¼ˆå¼ºæ··åˆï¼‰
- V ç¨³å®šæ€§ï¼šæ ‡å‡†å·® < 0.15 ä¸ºç¨³å®šï¼Œ> 0.3 ä¸ºæä¸ç¨³å®š
- C åˆ†ç±»ï¼š1 / 2 / â‰¥3

## å®ç°æ­¥éª¤

### 1. æ‰©å±•æ•°æ®æ¨¡å‹

**æ–‡ä»¶**: `Project_Color/Models/AnalysisModels.swift`

æ·»åŠ ä»¥ä¸‹æ–°ç»“æ„ï¼š

```swift
// åˆ†ææ¨¡å¼ï¼ˆè‡ªåŠ¨åˆ¤æ–­ï¼‰
enum AnalysisMode: String, Codable {
    case series = "ç»„å›¾æ¨¡å¼"
    case mixed = "æ··åˆæ¨¡å¼"
    case jumping = "è·³å˜å®¡ç¾å‹"
}

// æ¨¡å¼åˆ¤æ–­æŒ‡æ ‡
struct ModeDetectionMetrics: Codable {
    var sceneCount: Int              // S: åœºæ™¯æ•°é‡
    var offsetStability: Float       // V: åç§»ç¨³å®šæ€§ï¼ˆæ ‡å‡†å·®ï¼‰
    var subjectCategoryCount: Int    // C: ä¸»ä½“ç±»åˆ«æ•°
    
    var sceneNames: [String]         // åœºæ™¯åç§°åˆ—è¡¨
    var subjectCategories: [String]  // ä¸»ä½“ç±»åˆ«åˆ—è¡¨
    
    // åˆ¤æ–­ä¾æ®è¯´æ˜
    var detectionReason: String
}

// åœºæ™¯åŒ¹é…ç»“æœ
struct SceneMatchResult: Codable {
    var sceneName: String
    var score: Float
    var confidence: Float
    var baseline: SceneBaseline
    var isMixed: Bool                // æ˜¯å¦ä¸ºæ··åˆåœºæ™¯
    var mixedScenes: [String]?       // æ··åˆåœºæ™¯åˆ—è¡¨
}

// åœºæ™¯åŸºå‡†å‚æ•°
struct SceneBaseline: Codable {
    var colorTemp: (min: Float, max: Float)
    var brightness: (min: Float, max: Float)
    var contrast: (min: Float, max: Float)
    var saturation: (min: Float, max: Float)
    var shadowRatio: (min: Float, max: Float)
    var highlightRatio: (min: Float, max: Float)
}

// å®¡ç¾åç§»å‘é‡ï¼ˆ8ç»´ï¼‰
struct AestheticOffset: Codable {
    var brightnessOffset: Float      // äº®åº¦åç§»
    var contrastOffset: Float        // å¯¹æ¯”åº¦åç§»
    var warmCoolOffset: Float        // å†·æš–åç§»
    var saturationOffset: Float      // é¥±å’Œåç§»
    var hueDistribution: [Float]     // è‰²ç›¸åç§»ï¼ˆåˆ†æ®µï¼‰
    var shadowRetain: Float          // æš—éƒ¨ä¿ç•™ç¨‹åº¦
    var highlightCompress: Float     // é«˜å…‰å‹ç¼©
    var colorBalanceOffset: SIMD3<Float>  // RGB å‡è¡¡åç§»
}

// å®¡ç¾å€¾å‘
struct AestheticTendency: Codable {
    // è·¨åœºæ™¯æ ¸å¿ƒå®¡ç¾ï¼ˆç¨³å®šå‡ºç°çš„åç§»ï¼‰
    var crossSceneCore: [String: Float]
    
    // åœºæ™¯å†…é£æ ¼åå¥½
    var sceneSpecificStyles: [String: [String: Float]]
    
    // äººæ ¼ç±»å‹
    var personalityType: String      // "ç¨³å®šå‹" / "å®¡ç¾è·³å˜å‹" / "å¤šä¸»é¢˜å‹"
    var personalityDescription: String
}
```

åœ¨ `PhotoColorInfo` ä¸­æ·»åŠ ï¼š

```swift
var sceneMatch: SceneMatchResult?
var aestheticOffset: AestheticOffset?
var isExcluded: Bool = false
var subjectCategories: [String] = []  // ä¸»ä½“ç±»åˆ«
```

åœ¨ `AnalysisResult` ä¸­æ·»åŠ ï¼š

```swift
@Published var aestheticTendency: AestheticTendency? = nil
@Published var excludedPhotoCount: Int = 0
@Published var detectedMode: AnalysisMode? = nil
@Published var modeDetectionMetrics: ModeDetectionMetrics? = nil
```

### 2. åˆ›å»ºåœºæ™¯åŒ¹é…æœåŠ¡

**æ–°æ–‡ä»¶**: `Project_Color/Services/Vision/SceneMatcher.swift`

```swift
class SceneMatcher {
    private var primaryTags: [String: [String]] = [:]
    private var secondaryTags: [String: [String]] = [:]
    private var conflictTags: [String: [String]] = [:]
    private var sceneBaselines: [String: SceneBaseline] = [:]
    private var sceneLabelMapping: [String: [String]] = [:]
    
    init() {
        loadResources()
    }
    
    // åŠ è½½ JSON èµ„æº
    private func loadResources() {
        // åŠ è½½ primary_tags.json
        // åŠ è½½ scene_baseline.json
        // åŠ è½½ scene_label_mapping.json
    }
    
    // åˆ¤æ–­æ˜¯å¦åº”æ’é™¤ï¼ˆæˆªå±/æ–‡æ¡£ï¼‰
    func shouldExcludePhoto(visionInfo: PhotoVisionInfo) -> Bool {
        let excludeKeywords = ["screenshot", "document", "text", "receipt",
                               "invoice", "paper", "form", "menu"]
        
        // æ£€æŸ¥åœºæ™¯åˆ†ç±»
        for scene in visionInfo.sceneClassifications {
            if scene.confidence > 0.5 &&
               excludeKeywords.contains(where: { scene.identifier.lowercased().contains($0) }) {
                return true
            }
        }
        
        // æ£€æŸ¥å›¾åƒåˆ†ç±»
        for classification in visionInfo.imageClassifications {
            if classification.confidence > 0.5 &&
               excludeKeywords.contains(where: { classification.identifier.lowercased().contains($0) }) {
                return true
            }
        }
        
        return false
    }
    
    // åŒ¹é…åœºæ™¯
    func matchScene(visionInfo: PhotoVisionInfo) -> SceneMatchResult {
        // æ”¶é›†æ‰€æœ‰æ ‡ç­¾
        let labels = collectLabels(from: visionInfo)
        
        // è®¡ç®—æ¯ä¸ªåœºæ™¯çš„è¯„åˆ†
        var sceneScores: [(scene: String, score: Float)] = []
        for sceneName in sceneBaselines.keys {
            let score = calculateSceneScore(scene: sceneName, labels: labels)
            sceneScores.append((sceneName, score))
        }
        
        // æ’åº
        sceneScores.sort { $0.score > $1.score }
        
        // æ£€æŸ¥æ˜¯å¦éœ€è¦æ··åˆåœºæ™¯
        if sceneScores.count >= 2 {
            let topScore = sceneScores[0].score
            let secondScore = sceneScores[1].score
            
            // å¦‚æœå‰ä¸¤åè¯„åˆ†ç›¸è¿‘ï¼ˆå·®å€¼ < 10%ï¼‰ï¼Œç”Ÿæˆæ··åˆåœºæ™¯
            if (topScore - secondScore) / topScore < 0.1 {
                return createMixedScene(from: sceneScores.prefix(2).map { $0.scene })
            }
        }
        
        // å•ä¸€åœºæ™¯
        let topScene = sceneScores[0].scene
        return SceneMatchResult(
            sceneName: topScene,
            score: sceneScores[0].score,
            confidence: sceneScores[0].score / 10.0,  // å½’ä¸€åŒ–
            baseline: sceneBaselines[topScene]!,
            isMixed: false
        )
    }
    
    // è®¡ç®—åœºæ™¯è¯„åˆ†
    private func calculateSceneScore(scene: String, labels: [String]) -> Float {
        var primaryHitCount: Float = 0
        var secondaryHitCount: Float = 0
        var conflictPenalty: Float = 0
        
        // Primary hits
        if let primaries = primaryTags[scene] {
            primaryHitCount = Float(labels.filter { label in
                primaries.contains(where: { $0.lowercased() == label.lowercased() })
            }.count)
        }
        
        // Secondary hits
        if let secondaries = secondaryTags[scene] {
            secondaryHitCount = Float(labels.filter { label in
                secondaries.contains(where: { $0.lowercased() == label.lowercased() })
            }.count)
        }
        
        // Conflict penalty
        if let conflicts = conflictTags[scene] {
            conflictPenalty = Float(labels.filter { label in
                conflicts.contains(where: { $0.lowercased() == label.lowercased() })
            }.count)
        }
        
        // è¯„åˆ†å…¬å¼
        return 3 * primaryHitCount + 1 * secondaryHitCount - 2 * conflictPenalty
    }
    
    // åˆ›å»ºæ··åˆåœºæ™¯
    private func createMixedScene(from scenes: [String]) -> SceneMatchResult {
        // åŠ æƒå¹³å‡ç”Ÿæˆæ··åˆåŸºå‡†
        let baselines = scenes.compactMap { sceneBaselines[$0] }
        let mixedBaseline = weightedAverageBaseline(baselines)
        
        return SceneMatchResult(
            sceneName: scenes.joined(separator: "+"),
            score: 0,
            confidence: 0.8,
            baseline: mixedBaseline,
            isMixed: true,
            mixedScenes: scenes
        )
    }
    
    // æå–ä¸»ä½“ç±»åˆ«
    func extractSubjectCategories(visionInfo: PhotoVisionInfo) -> [String] {
        var categories = Set<String>()
        
        // åŸºäºå›¾åƒåˆ†ç±»è¯†åˆ«ä¸»ä½“
        let subjectKeywords = [
            "person", "face", "portrait": "äººç‰©",
            "building", "architecture", "street": "è¡—æ™¯",
            "food", "dish", "meal": "é£Ÿç‰©",
            "plant", "flower", "tree": "æ¤ç‰©",
            "animal", "dog", "cat": "åŠ¨ç‰©",
            "sky", "cloud", "sunset": "å¤©ç©º",
            "water", "sea", "ocean": "æ°´ä½“"
        ]
        
        for classification in visionInfo.imageClassifications {
            if classification.confidence > 0.3 {
                for (keywords, category) in subjectKeywords {
                    if keywords.split(separator: ",").contains(where: {
                        classification.identifier.lowercased().contains($0.trimmingCharacters(in: .whitespaces))
                    }) {
                        categories.insert(category)
                    }
                }
            }
        }
        
        return Array(categories)
    }
}
```

### 3. åˆ›å»ºæ¨¡å¼æ£€æµ‹å™¨

**æ–°æ–‡ä»¶**: `Project_Color/Services/ColorAnalysis/ModeDetector.swift`

```swift
class ModeDetector {
    
    // è‡ªåŠ¨æ£€æµ‹åˆ†ææ¨¡å¼
    func detectMode(photoInfos: [PhotoColorInfo]) -> (AnalysisMode, ModeDetectionMetrics) {
        // è®¡ç®— S: åœºæ™¯æ•°é‡
        let sceneNames = Set(photoInfos.compactMap { $0.sceneMatch?.sceneName })
        let S = sceneNames.count
        
        // è®¡ç®— C: ä¸»ä½“ç±»åˆ«æ•°
        let allSubjects = photoInfos.flatMap { $0.subjectCategories }
        let uniqueSubjects = Set(allSubjects)
        let C = uniqueSubjects.count
        
        // è®¡ç®— V: åç§»ç¨³å®šæ€§
        let V = calculateOffsetStability(photoInfos: photoInfos)
        
        // æ„å»ºæŒ‡æ ‡
        let metrics = ModeDetectionMetrics(
            sceneCount: S,
            offsetStability: V,
            subjectCategoryCount: C,
            sceneNames: Array(sceneNames),
            subjectCategories: Array(uniqueSubjects),
            detectionReason: ""
        )
        
        // åˆ¤æ–­æ¨¡å¼
        let mode = determineMode(S: S, V: V, C: C, metrics: &metrics)
        
        return (mode, metrics)
    }
    
    // è®¡ç®—åç§»ç¨³å®šæ€§ï¼ˆæ ‡å‡†å·®ï¼‰
    private func calculateOffsetStability(photoInfos: [PhotoColorInfo]) -> Float {
        let offsets = photoInfos.compactMap { $0.aestheticOffset }
        guard !offsets.isEmpty else { return 0 }
        
        // è®¡ç®—å„ç»´åº¦çš„æ ‡å‡†å·®ï¼Œå–å¹³å‡
        let brightnessStd = standardDeviation(offsets.map { $0.brightnessOffset })
        let contrastStd = standardDeviation(offsets.map { $0.contrastOffset })
        let warmCoolStd = standardDeviation(offsets.map { $0.warmCoolOffset })
        let saturationStd = standardDeviation(offsets.map { $0.saturationOffset })
        
        return (brightnessStd + contrastStd + warmCoolStd + saturationStd) / 4.0
    }
    
    // åˆ¤æ–­æ¨¡å¼
    private func determineMode(S: Int, V: Float, C: Int, metrics: inout ModeDetectionMetrics) -> AnalysisMode {
        // è·³å˜å®¡ç¾å‹ï¼šV æä¸ç¨³å®š ä¸” Sâ‰¥3
        if V > 0.3 && S >= 3 {
            metrics.detectionReason = "åç§»å‘é‡æä¸ç¨³å®š(V=\(String(format: "%.2f", V)))ä¸”åœºæ™¯æ•°â‰¥3ï¼Œåˆ¤å®šä¸ºè·³å˜å®¡ç¾å‹"
            return .jumping
        }
        
        // æ··åˆæ¨¡å¼ï¼šSâ‰¥2 æˆ– Câ‰¥3
        if S >= 2 || C >= 3 {
            metrics.detectionReason = "åœºæ™¯æ•°=\(S)æˆ–ä¸»ä½“ç±»åˆ«æ•°=\(C)â‰¥3ï¼Œåˆ¤å®šä¸ºæ··åˆæ¨¡å¼"
            return .mixed
        }
        
        // ç»„å›¾æ¨¡å¼ï¼šS=1 ä¸” Câ‰¤2 ä¸” Vç¨³å®š
        if S == 1 && C <= 2 && V < 0.15 {
            metrics.detectionReason = "å•åœºæ™¯(S=1)ã€ä¸»ä½“ç±»åˆ«â‰¤2ã€åç§»ç¨³å®š(V=\(String(format: "%.2f", V)))ï¼Œåˆ¤å®šä¸ºç»„å›¾æ¨¡å¼"
            return .series
        }
        
        // é»˜è®¤ï¼šæ··åˆæ¨¡å¼
        metrics.detectionReason = "é»˜è®¤åˆ¤å®šä¸ºæ··åˆæ¨¡å¼"
        return .mixed
    }
    
    // æ ‡å‡†å·®è®¡ç®—
    private func standardDeviation(_ values: [Float]) -> Float {
        guard !values.isEmpty else { return 0 }
        let mean = values.reduce(0, +) / Float(values.count)
        let variance = values.map { pow($0 - mean, 2) }.reduce(0, +) / Float(values.count)
        return sqrt(variance)
    }
}
```

### 4. åˆ›å»ºå®¡ç¾åç§»è®¡ç®—å™¨

**æ–°æ–‡ä»¶**: `Project_Color/Services/ColorAnalysis/AestheticOffsetCalculator.swift`

æ ¸å¿ƒé€»è¾‘ï¼ˆ~500è¡Œï¼‰ï¼š

```swift
class AestheticOffsetCalculator {
    private let colorConverter = ColorSpaceConverter()
    
    func calculateOffset(
        image: CGImage,
        sceneBaseline: SceneBaseline,
        dominantColors: [DominantColor],
        saliencyObjects: [SaliencyObject],
        mode: AnalysisMode
    ) async -> AestheticOffset {
        
        // 1. æå–åƒç´ æ•°æ®
        let pixels = extractPixels(from: image)
        
        // 2. ç¯å¢ƒå™ªå£°è¿‡æ»¤ï¼šåªä¿ç•™è¶…å‡ºåœºæ™¯åŸºå‡†èŒƒå›´çš„åƒç´ 
        let aestheticPixels = filterEnvironmentalNoise(
            pixels: pixels,
            baseline: sceneBaseline
        )
        
        // 3. ä¸»ä½“è‰²åŸŸäºŒæ¬¡è¿‡æ»¤ï¼ˆä»…æ··åˆæ¨¡å¼ï¼‰
        let finalPixels: [Pixel]
        if mode == .mixed {
            finalPixels = filterBySubjectColorRange(
                pixels: aestheticPixels,
                saliencyObjects: saliencyObjects
            )
        } else {
            finalPixels = aestheticPixels
        }
        
        // 4. è®¡ç®—8ç»´åç§»å‘é‡
        return AestheticOffset(
            brightnessOffset: calculateBrightnessOffset(finalPixels, baseline: sceneBaseline),
            contrastOffset: calculateContrastOffset(finalPixels, baseline: sceneBaseline),
            warmCoolOffset: calculateWarmCoolOffset(finalPixels, baseline: sceneBaseline),
            saturationOffset: calculateSaturationOffset(finalPixels, baseline: sceneBaseline),
            hueDistribution: calculateHueDistribution(finalPixels),
            shadowRetain: calculateShadowRetain(finalPixels, baseline: sceneBaseline),
            highlightCompress: calculateHighlightCompress(finalPixels, baseline: sceneBaseline),
            colorBalanceOffset: calculateColorBalanceOffset(finalPixels)
        )
    }
    
    // ç¯å¢ƒå™ªå£°è¿‡æ»¤ï¼šåªä¿ç•™è¶…å‡ºåœºæ™¯åŸºå‡†èŒƒå›´çš„åƒç´ 
    private func filterEnvironmentalNoise(
        pixels: [Pixel],
        baseline: SceneBaseline
    ) -> [Pixel] {
        return pixels.filter { pixel in
            let brightness = pixel.lightness
            let saturation = pixel.saturation
            
            // åˆ¤æ–­æ˜¯å¦åœ¨åœºæ™¯åˆç†èŒƒå›´å†…
            let isInBrightnessRange = (baseline.brightness.min...baseline.brightness.max).contains(brightness)
            let isInSaturationRange = (baseline.saturation.min...baseline.saturation.max).contains(saturation)
            
            // åªä¿ç•™è¶…å‡ºèŒƒå›´çš„åƒç´ ï¼ˆç”¨æˆ·è°ƒè‰²çš„ç»“æœï¼‰
            return !isInBrightnessRange || !isInSaturationRange
        }
    }
    
    // ä¸»ä½“è‰²åŸŸäºŒæ¬¡è¿‡æ»¤ï¼ˆæ··åˆæ¨¡å¼ä¸“ç”¨ï¼‰
    private func filterBySubjectColorRange(
        pixels: [Pixel],
        saliencyObjects: [SaliencyObject]
    ) -> [Pixel] {
        // åŠ è½½ subject_color_dictionary.json
        let subjectRanges = loadSubjectColorRanges()
        
        return pixels.filter { pixel in
            // æ’é™¤ä¸»ä½“å›ºæœ‰è‰²ï¼ˆå¦‚å¤©ç©ºçš„è“è‰²ï¼‰
            let isSubjectColor = subjectRanges.contains { range in
                range.hue.contains(pixel.hue) &&
                range.saturation.contains(pixel.saturation) &&
                range.value.contains(pixel.value)
            }
            return !isSubjectColor
        }
    }
    
    // 8ä¸ªç»´åº¦çš„è®¡ç®—æ–¹æ³•ï¼ˆçœç•¥å…·ä½“å®ç°ï¼‰
    private func calculateBrightnessOffset(...) -> Float { ... }
    private func calculateContrastOffset(...) -> Float { ... }
    private func calculateWarmCoolOffset(...) -> Float { ... }
    private func calculateSaturationOffset(...) -> Float { ... }
    private func calculateHueDistribution(...) -> [Float] { ... }
    private func calculateShadowRetain(...) -> Float { ... }
    private func calculateHighlightCompress(...) -> Float { ... }
    private func calculateColorBalanceOffset(...) -> SIMD3<Float> { ... }
}
```

### 5. åˆ›å»ºå®¡ç¾å€¾å‘åˆ†æå™¨

**æ–°æ–‡ä»¶**: `Project_Color/Services/ColorAnalysis/AestheticTendencyAnalyzer.swift`

```swift
class AestheticTendencyAnalyzer {
    
    func analyzeAestheticTendency(
        photoInfos: [PhotoColorInfo],
        mode: AnalysisMode
    ) -> AestheticTendency {
        
        switch mode {
        case .series:
            return analyzeSeriesMode(photoInfos: photoInfos)
        case .mixed:
            return analyzeMixedMode(photoInfos: photoInfos)
        case .jumping:
            return analyzeJumpingMode(photoInfos: photoInfos)
        }
    }
    
    // ç»„å›¾æ¨¡å¼ï¼šåœºæ™¯å†…ç‰¹å¾é‡å¤ç»Ÿè®¡
    private func analyzeSeriesMode(photoInfos: [PhotoColorInfo]) -> AestheticTendency {
        // ç»Ÿè®¡é‡å¤ç‰¹å¾ï¼ˆå¦‚æš—éƒ¨ä¿ç•™ã€é«˜å…‰å‹ç¼©ç­‰ï¼‰
        let offsets = photoInfos.compactMap { $0.aestheticOffset }
        
        // è®¡ç®—å¹³å‡åç§»
        var coreOffsets: [String: Float] = [:]
        coreOffsets["shadowRetain"] = offsets.map { $0.shadowRetain }.reduce(0, +) / Float(offsets.count)
        coreOffsets["highlightCompress"] = offsets.map { $0.highlightCompress }.reduce(0, +) / Float(offsets.count)
        
        return AestheticTendency(
            crossSceneCore: [:],
            sceneSpecificStyles: [:],
            personalityType: "ç¨³å®šå‹",
            personalityDescription: "åœºæ™¯å†…ç‰¹å¾é‡å¤å‡ºç°"
        )
    }
    
    // æ··åˆæ¨¡å¼ï¼šè·¨åœºæ™¯ä¸€è‡´æ€§è¿‡æ»¤
    private func analyzeMixedMode(photoInfos: [PhotoColorInfo]) -> AestheticTendency {
        // æå–è·¨åœºæ™¯æ ¸å¿ƒå®¡ç¾
        let crossSceneCore = extractCrossSceneCore(photoInfos: photoInfos)
        
        return AestheticTendency(
            crossSceneCore: crossSceneCore,
            sceneSpecificStyles: [:],
            personalityType: crossSceneCore.isEmpty ? "å¤šä¸»é¢˜å‹" : "ç¨³å®šå‹",
            personalityDescription: "è·¨åœºæ™¯ç¨³å®šåç§»"
        )
    }
    
    // è·³å˜å®¡ç¾å‹
    private func analyzeJumpingMode(photoInfos: [PhotoColorInfo]) -> AestheticTendency {
        return AestheticTendency(
            crossSceneCore: [:],
            sceneSpecificStyles: [:],
            personalityType: "å®¡ç¾è·³å˜å‹",
            personalityDescription: "åç§»å‘é‡è·³è·ƒæ˜æ˜¾ï¼Œæ— ç»Ÿä¸€å®¡ç¾"
        )
    }
    
    // æå–è·¨åœºæ™¯æ ¸å¿ƒå®¡ç¾ï¼šè‡³å°‘3ä¸ªåœºæ™¯çš„åç§»é‡ > é˜ˆå€¼
    private func extractCrossSceneCore(photoInfos: [PhotoColorInfo]) -> [String: Float] {
        // æŒ‰åœºæ™¯åˆ†ç»„
        var sceneGroups: [String: [AestheticOffset]] = [:]
        for info in photoInfos {
            guard let sceneName = info.sceneMatch?.sceneName,
                  let offset = info.aestheticOffset else { continue }
            sceneGroups[sceneName, default: []].append(offset)
        }
        
        // è‡³å°‘3ä¸ªåœºæ™¯
        guard sceneGroups.count >= 3 else { return [:] }
        
        // æ£€æŸ¥å„ç»´åº¦çš„è·¨åœºæ™¯ä¸€è‡´æ€§
        var coreOffsets: [String: Float] = [:]
        
        for dimension in ["brightness", "warmCool", "saturation", "contrast"] {
            let sceneAverages = sceneGroups.mapValues { offsets in
                offsets.map { getDimensionValue($0, dimension: dimension) }.reduce(0, +) / Float(offsets.count)
            }
            
            // åˆ¤æ–­æ˜¯å¦è·¨åœºæ™¯ä¸€è‡´
            let values = Array(sceneAverages.values)
            let mean = values.reduce(0, +) / Float(values.count)
            let allPositive = values.allSatisfy { $0 > 0.2 }
            let allNegative = values.allSatisfy { $0 < -0.2 }
            
            if allPositive || allNegative {
                coreOffsets[dimension] = mean
            }
        }
        
        return coreOffsets
    }
}
```

### 6. é›†æˆåˆ°åˆ†æç®¡çº¿

**ä¿®æ”¹æ–‡ä»¶**: `Project_Color/Services/ColorAnalysis/SimpleAnalysisPipeline.swift`

åœ¨ `analyzePhotos` æ–¹æ³•ä¸­æ·»åŠ æ–°é˜¶æ®µï¼š

```swift
// åˆå§‹åŒ–æ–°æœåŠ¡
private let sceneMatcher = SceneMatcher()
private let modeDetector = ModeDetector()
private let offsetCalculator = AestheticOffsetCalculator()
private let tendencyAnalyzer = AestheticTendencyAnalyzer()

// åœ¨ analyzePhotos æ–¹æ³•ä¸­ï¼š

// é˜¶æ®µ 1: Vision åˆ†æ + åœºæ™¯åŒ¹é… + æ’é™¤æˆªå±
var excludedCount = 0
for (index, asset) in assets.enumerated() {
    let image = await requestImage(for: asset)
    let visionInfo = await visionAnalyzer.analyzeImage(image)
    
    // æ’é™¤æˆªå±/æ–‡æ¡£
    if sceneMatcher.shouldExcludePhoto(visionInfo: visionInfo) {
        excludedCount += 1
        continue
    }
    
    // åœºæ™¯åŒ¹é…
    let sceneMatch = sceneMatcher.matchScene(visionInfo: visionInfo)
    let subjectCategories = sceneMatcher.extractSubjectCategories(visionInfo: visionInfo)
    
    photoInfo.sceneMatch = sceneMatch
    photoInfo.visionInfo = visionInfo
    photoInfo.subjectCategories = subjectCategories
}

result.excludedPhotoCount = excludedCount

// é˜¶æ®µ 2: è‡ªåŠ¨æ£€æµ‹æ¨¡å¼
let (detectedMode, metrics) = modeDetector.detectMode(photoInfos: photoInfos)
result.detectedMode = detectedMode
result.modeDetectionMetrics = metrics

print("ğŸ¯ è‡ªåŠ¨æ£€æµ‹æ¨¡å¼: \(detectedMode.rawValue)")
print("   åœºæ™¯æ•°: \(metrics.sceneCount), ç¨³å®šæ€§: \(metrics.offsetStability), ä¸»ä½“ç±»åˆ«æ•°: \(metrics.subjectCategoryCount)")

// é˜¶æ®µ 3: è®¡ç®—å®¡ç¾åç§»
for photoInfo in photoInfos {
    let offset = await offsetCalculator.calculateOffset(
        image: image,
        sceneBaseline: photoInfo.sceneMatch!.baseline,
        dominantColors: photoInfo.dominantColors,
        saliencyObjects: photoInfo.visionInfo!.saliencyObjects,
        mode: detectedMode
    )
    photoInfo.aestheticOffset = offset
}

// é˜¶æ®µ 4: æç‚¼å®¡ç¾å€¾å‘
let tendency = tendencyAnalyzer.analyzeAestheticTendency(
    photoInfos: photoInfos,
    mode: detectedMode
)
result.aestheticTendency = tendency
```

### 7. æ‰©å±• AI è¯„ä»·æç¤ºè¯

**ä¿®æ”¹æ–‡ä»¶**: `Project_Color/Services/AI/ColorAnalysisEvaluator.swift`

åœ¨ `systemPrompt` ä¸­æ·»åŠ ï¼š

```
- detected_mode: "ç»„å›¾æ¨¡å¼" | "æ··åˆæ¨¡å¼" | "è·³å˜å®¡ç¾å‹"
- mode_detection_metrics: { scene_count, offset_stability, subject_category_count }
- aesthetic_tendency: {
    cross_scene_core: { brightness_offset, warm_cool_offset, ... },
    scene_specific_styles: { ... },
    personality_type: "ç¨³å®šå‹" | "å®¡ç¾è·³å˜å‹" | "å¤šä¸»é¢˜å‹"
  }

æ ¹æ® detected_mode è°ƒæ•´è¾“å‡ºé£æ ¼ï¼š
- ç»„å›¾æ¨¡å¼ + å•ä¸€ä¸»ä½“ç±»åˆ«ï¼šä½¿ç”¨ä¸“ä¸šæœ¯è¯­ï¼ˆè¡—æ‹=åŸå¸‚è‚Œç†/å…‰å½±åˆ‡å‰²ï¼Œäººåƒ=è‚¤è‰²æƒ…æ„Ÿ/ä¸»ä½“ç–ç¦»æ„Ÿï¼‰
- æ··åˆæ¨¡å¼ï¼šæè¿°è·¨åœºæ™¯çš„ç¨³å®šåç§»å‘é‡
- è·³å˜å®¡ç¾å‹ï¼šç›´æ¥è¾“å‡ºäººæ ¼æ ‡ç­¾ï¼Œä¸å¼ºè¡Œå½’çº³
```

### 8. UI å±•ç¤º

**ä¿®æ”¹æ–‡ä»¶**: `Project_Color/Views/AnalysisResultView.swift`

åœ¨ "AIè¯„ä»·" æ ‡ç­¾é¡µæ·»åŠ ï¼š

```swift
// æ¨¡å¼æ£€æµ‹å¡ç‰‡
if let metrics = result.modeDetectionMetrics,
   let mode = result.detectedMode {
    VStack(alignment: .leading, spacing: 8) {
        HStack {
            Image(systemName: "brain")
            Text("è‡ªåŠ¨æ£€æµ‹æ¨¡å¼")
                .font(.headline)
        }
        
        Text(mode.rawValue)
            .font(.title3)
            .fontWeight(.semibold)
        
        Text(metrics.detectionReason)
            .font(.caption)
            .foregroundColor(.secondary)
        
        HStack(spacing: 16) {
            MetricBadge(label: "åœºæ™¯æ•°", value: "\(metrics.sceneCount)")
            MetricBadge(label: "ç¨³å®šæ€§", value: String(format: "%.2f", metrics.offsetStability))
            MetricBadge(label: "ä¸»ä½“ç±»åˆ«", value: "\(metrics.subjectCategoryCount)")
        }
    }
    .padding()
    .background(Color(.systemGray6))
    .cornerRadius(12)
}

// å®¡ç¾å€¾å‘å¡ç‰‡
if let tendency = result.aestheticTendency {
    // ... (å±•ç¤ºè·¨åœºæ™¯æ ¸å¿ƒå®¡ç¾æˆ–åœºæ™¯å†…é£æ ¼)
}
```

### 9. Core Data æŒä¹…åŒ–

**ä¿®æ”¹æ–‡ä»¶**: `Project_Color.xcdatamodeld/Project_Color.xcdatamodel/contents`

åœ¨ `AnalysisSessionEntity` ä¸­æ·»åŠ ï¼š

- `aestheticTendencyData: Binary Data?`
- `excludedPhotoCount: Int16`
- `detectedMode: String?`
- `modeDetectionMetricsData: Binary Data?`

åœ¨ `PhotoColorEntity` ä¸­æ·»åŠ ï¼š

- `sceneMatchData: Binary Data?`
- `aestheticOffsetData: Binary Data?`
- `isExcluded: Bool`
- `subjectCategoriesData: Binary Data?`

### 10. èµ„æºæ–‡ä»¶è¡¥å……

**æ£€æŸ¥å¹¶è¡¥å……**: `Project_Color/Resources/primary_tags.json`

ç¡®ä¿åŒ…å«å®Œæ•´çš„ primary/secondary/conflict æ ‡ç­¾å®šä¹‰ï¼š

```json
{
  "primary": { ... },
  "secondary": {
    "indoor_warm_light": ["furniture", "lamp", "shadow", "reflection", ...],
    "daylight_sunny": ["tree", "grass", "shadow", "sunlight", ...],
    ...
  },
  "conflict": {
    "indoor_warm_light": ["outdoor", "daylight", "sunny", ...],
    "daylight_sunny": ["indoor", "night", "artificial light", ...],
    ...
  }
}
```

## æ–‡ä»¶æ¸…å•

### æ–°å»ºæ–‡ä»¶

1. `Project_Color/Services/Vision/SceneMatcher.swift` (~350 è¡Œ)
2. `Project_Color/Services/ColorAnalysis/ModeDetector.swift` (~200 è¡Œ)
3. `Project_Color/Services/ColorAnalysis/AestheticOffsetCalculator.swift` (~550 è¡Œ)
4. `Project_Color/Services/ColorAnalysis/AestheticTendencyAnalyzer.swift` (~450 è¡Œ)

### ä¿®æ”¹æ–‡ä»¶

1. `Project_Color/Models/AnalysisModels.swift` (+200 è¡Œ)
2. `Project_Color/Services/ColorAnalysis/SimpleAnalysisPipeline.swift` (+120 è¡Œ)
3. `Project_Color/Services/AI/ColorAnalysisEvaluator.swift` (+100 è¡Œ)
4. `Project_Color/Views/AnalysisResultView.swift` (+180 è¡Œ)
5. `Project_Color/Persistence/CoreDataManager.swift` (+60 è¡Œ)
6. `Project_Color.xcdatamodeld/Project_Color.xcdatamodel/contents` (æ·»åŠ å­—æ®µ)

### èµ„æºæ–‡ä»¶

1. è¡¥å…… `Project_Color/Resources/primary_tags.json` (secondary å’Œ conflict æ ‡ç­¾)

## é¢„è®¡å·¥ä½œé‡

- æ•°æ®æ¨¡å‹æ‰©å±•ï¼š1.5 å°æ—¶
- åœºæ™¯åŒ¹é…æœåŠ¡ï¼š2.5 å°æ—¶
- æ¨¡å¼æ£€æµ‹å™¨ï¼š1.5 å°æ—¶
- å®¡ç¾åç§»è®¡ç®—å™¨ï¼š3.5 å°æ—¶
- å®¡ç¾å€¾å‘åˆ†æå™¨ï¼š2.5 å°æ—¶
- ç®¡çº¿é›†æˆï¼š1.5 å°æ—¶
- AI æç¤ºè¯æ‰©å±•ï¼š1 å°æ—¶
- UI å®ç°ï¼š2.5 å°æ—¶
- Core Data æŒä¹…åŒ–ï¼š1 å°æ—¶
- èµ„æºæ–‡ä»¶è¡¥å……ï¼š0.5 å°æ—¶
- æµ‹è¯•ä¸è°ƒè¯•ï¼š2 å°æ—¶

**æ€»è®¡**ï¼šçº¦ 20 å°æ—¶
